{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMyw9Qj_Q5F8"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApgBN_OUMDeY"
      },
      "source": [
        "# Connect to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6dTZKFgMAn0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for hardware and versions"
      ],
      "metadata": {
        "id": "zbLxVDd_Rsmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba.cuda.cudadrv import enums\n",
        "from numba import cuda\n",
        "\n",
        "import transformers\n",
        "\n",
        "# device = cuda.get_current_device()\n",
        "# attribs= [name.replace(\"CU_DEVICE_ATTRIBUTE_\", \"\") for name in dir(enums) if name.startswith(\"CU_DEVICE_ATTRIBUTE_\")]\n",
        "# for attr in attribs:\n",
        "#     print(attr, '=', getattr(device, attr))\n",
        "\n",
        "print(f'transformers version: {transformers.__version__}')\n"
      ],
      "metadata": {
        "id": "56lCO4bILSEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVd5EhiTMOsl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEtLvONoMJ9O"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymayMKc0MrVT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "random_state = 42 # for reproducibility\n",
        "\n",
        "OVERALL_RATING = 'overall_rating'\n",
        "REVIEW_TEXT = 'review_text'\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/B2W-Reviews01.csv', parse_dates=['submission_date'], low_memory=False)\n",
        "print(df.dtypes)\n",
        "print('Data size: ' + str(len(df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Processing of Data"
      ],
      "metadata": {
        "id": "GGosF-HG7YVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the samples"
      ],
      "metadata": {
        "id": "idz_o-XUvRbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAMPLE_SIZE = 15000\n",
        "SAMPLE_SIZE = 3000\n",
        "\n",
        "# Drop rows with null values in 'review_text' column and select a sample\n",
        "samples = df.dropna(subset = [REVIEW_TEXT])\n",
        "\n",
        "# Drops samples with 3 stars, as they will be considered neutral\n",
        "samples = samples[samples[OVERALL_RATING] != 3]\n",
        "\n",
        "samples = samples.sample(\n",
        "    n=SAMPLE_SIZE,\n",
        "    random_state=random_state\n",
        ")"
      ],
      "metadata": {
        "id": "Uze6MXUKvLLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'samples size is {len(samples)}')"
      ],
      "metadata": {
        "id": "RzKeJTF-7VJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Training and Evaluation"
      ],
      "metadata": {
        "id": "nmlwh_Nt7bwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create X and Y values"
      ],
      "metadata": {
        "id": "BQJ8TIz47sb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = samples[REVIEW_TEXT].values\n",
        "\n",
        "Y = samples[OVERALL_RATING]\n",
        "\n",
        "# Maps 1 and 2 stars as negative reviews, and 4 and 5 stars as positive reviews\n",
        "Y = Y.map({1:0, 2:0, 4: 1, 5: 1}).values\n",
        "\n",
        "print('X values:')\n",
        "print(X)\n",
        "\n",
        "print('\\nY values:')\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "GD-YSc997whw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separate training and test"
      ],
      "metadata": {
        "id": "FT6x05sW9NzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_PERCENTAGE = 0.2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_PERCENTAGE, random_state=random_state)"
      ],
      "metadata": {
        "id": "DQWYqR7-9QKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balance the training data"
      ],
      "metadata": {
        "id": "2DFnkIrq9c4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "print(f'X_train length: {len(X_train)}')\n",
        "print(X_train)\n",
        "\n",
        "reshaped_X_train = X_train.reshape(-1, 1)\n",
        "print(reshaped_X_train)\n",
        "\n",
        "print(f'\\n\\nY_train length: {len(Y_train)}')\n",
        "print(Y_train)\n",
        "\n",
        "Y_train_series = pd.Series(Y_train)\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, Y_train_resampled = undersampler.fit_resample(reshaped_X_train, Y_train)\n",
        "\n",
        "X_train_resampled = X_train_resampled.flatten()\n",
        "\n",
        "print(f'\\n\\nX_train_resampled length: {len(X_train_resampled)}')\n",
        "print(X_train_resampled)\n",
        "\n",
        "print(f'\\n\\nY_train_resampled length: {len(Y_train_resampled)}')\n",
        "\n",
        "X_train_resampled = shuffle(X_train_resampled, random_state=random_state)\n",
        "Y_train_resampled = shuffle(Y_train_resampled, random_state=random_state)\n",
        "\n",
        "print(f'\\n\\nX_test length: {len(X_test)}')\n",
        "print(X_test)\n",
        "\n",
        "print(f'\\n\\nY_test length: {len(Y_test)}')\n",
        "print(Y_test)"
      ],
      "metadata": {
        "id": "nLdU7xc29feB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize data"
      ],
      "metadata": {
        "id": "clUNPxvl-KML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "9KZ0BA7G-OIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create train inputs"
      ],
      "metadata": {
        "id": "ctk2vVZn_npZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSu4u0B7NqPe"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sent in tqdm(data):\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,             # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad or Truncate sentences to max length\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "\n",
        "# Testing with first sentence\n",
        "MAX_LEN = 510  # As that is the max length that is generally encoded.\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0] )\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Tokenizing all data\n",
        "print('Tokenizing Data')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train_resampled)\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0KI31QgRcvt"
      },
      "source": [
        "# Creating PyTorch Dataloader\n",
        "\n",
        "A dataloader allows for faster loading of data, thus making the training more efficient and it also helps to save on memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GYAyFqaRhjx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(np.array(Y_train_resampled))\n",
        "test_labels = torch.tensor(np.array(Y_test))\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size =  16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "print(len(train_inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84lI-NdCSkb7"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4AAg4V5SqgW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        # self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        # self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.bert = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size, max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size, num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQhSUn2STqv9"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "The authors recommend following hyper-parameters:\n",
        "\n",
        "Batch size:\n",
        "* 16 or 32\n",
        "* Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
        "* Number of epochs: 2, 3, 4\n",
        "\n",
        "Huggingface provided the run_glue.py script, an examples of implementing the transformers library. In the script, the AdamW optimizer is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTPzRseWTouA"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(\n",
        "        bert_classifier.parameters(),\n",
        "        lr=3e-5,    # Default learning rate\n",
        "        eps=1e-8    # Default epsilon value\n",
        "    )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=10, # Default value\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "    return bert_classifier, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeNEwucVUMfT"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az3TB8LPUNwr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"\n",
        "    Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    start_epoch = 0\n",
        "    checkpoint_path = \"/content/drive/MyDrive/Datasets/bert_checkpoint.pth\"\n",
        "\n",
        "    # Check if there is a saved checkpoint\n",
        "    if os.path.isfile(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f'Loaded checkpoint from epoch {start_epoch}\\n')\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(start_epoch, epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\" * 70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "        torch.save({\n",
        "            'epoch': epoch_i + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, checkpoint_path)\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"\n",
        "    After the completion of each training epoch, measure the model's performance on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leXqlYIOVqIh"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "set_seed(random_state)    # Set seed for reproducibility\n",
        "t1 = time.time()\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, test_dataloader, epochs=4, evaluation=True)\n",
        "t2 = time.time()\n",
        "print(f'\\nTook: {t2 - t1} seconds to run')\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt-dEBGbVBgo"
      },
      "source": [
        "# Evaluation on validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y11nnBvJVD_g"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "\n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4Vkgy61VLwA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "\n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy of BERT model: {accuracy*100:.2f}%')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    print(f'Recall of BERT model: {recall}')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f'F1 Score of BERT model: {f1}')\n",
        "\n",
        "\n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    data = confusion_matrix(y_true, y_pred)\n",
        "    data.astype(int)\n",
        "    plot_confusion_matrix(data, labels=['negative', 'positive'])\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(data, labels):\n",
        "  \"\"\"Plot confusion matrix using heatmap.\n",
        "  Args:\n",
        "      data (list of list): List of lists with confusion matrix data.\n",
        "      labels (list): Labels which will be plotted across x and y axis.\n",
        "      output_filename (str): Path to output file.\n",
        "  \"\"\"\n",
        "  seaborn.set(color_codes=True)\n",
        "  plt.figure(1, figsize=(9, 6))\n",
        "\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "\n",
        "  seaborn.set(font_scale=1.4)\n",
        "  ax = seaborn.heatmap(data, annot=True, fmt='d', cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
        "\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.set_yticklabels(labels)\n",
        "\n",
        "  ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
        "\n",
        "  # plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yYsYNQvVQJX"
      },
      "outputs": [],
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "t1 = time.time()\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "t2 = time.time()\n",
        "print(f'\\nTook: {t2 - t1} seconds to run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9DF49IITtJ6"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Bert classifier\n",
        "t1 = time.time()\n",
        "evaluate_roc(probs, Y_test)\n",
        "t2 = time.time()\n",
        "print(f'\\nTook: {t2 - t1} seconds to run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI385M3TVVkI"
      },
      "outputs": [],
      "source": [
        "torch.save(bert_classifier.state_dict(), \"/content/drive/MyDrive/Datasets/bert_news_sentiment.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}