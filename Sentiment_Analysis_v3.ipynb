{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Connect to the Dataset (Google Collab only)"
      ],
      "metadata": {
        "id": "iH0zSw6Lc8Cn"
      },
      "id": "iH0zSw6Lc8Cn"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NlHkZycscuBr"
      },
      "id": "NlHkZycscuBr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check hardware and versions"
      ],
      "metadata": {
        "id": "uT0p7ZHDih2U"
      },
      "id": "uT0p7ZHDih2U"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, platform, subprocess, re\n",
        "\n",
        "import sys\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import imblearn\n",
        "\n",
        "def get_processor_name():\n",
        "    if platform.system() == \"Windows\":\n",
        "        return platform.processor()\n",
        "    elif platform.system() == \"Darwin\":\n",
        "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin'\n",
        "        command =\"sysctl -n machdep.cpu.brand_string\"\n",
        "        return subprocess.check_output(command).strip()\n",
        "    elif platform.system() == \"Linux\":\n",
        "        command = \"cat /proc/cpuinfo\"\n",
        "        all_info = subprocess.check_output(command, shell=True).decode().strip()\n",
        "        for line in all_info.split(\"\\n\"):\n",
        "            if \"model name\" in line:\n",
        "                return re.sub( \".*model name.*:\", \"\", line,1)\n",
        "    return \"\"\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Processor: {get_processor_name()}\")\n",
        "print(f\"sklearn version: {sklearn.__version__}\")\n",
        "print(f\"pandas version: {pd.__version__}\")\n",
        "print(f\"nltk version: {nltk.__version__}\")\n",
        "print(f\"imbalanced-learn version: {imblearn.__version__}\")"
      ],
      "metadata": {
        "id": "Xyoos-oSIkhK"
      },
      "id": "Xyoos-oSIkhK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "60b21a4f",
      "metadata": {
        "id": "60b21a4f"
      },
      "source": [
        "## 2. Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98ddfe6",
      "metadata": {
        "id": "f98ddfe6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "random_state = 42 # for reproducibility\n",
        "\n",
        "# Global constants\n",
        "SUBMISSION_DATE = 'submission_date'\n",
        "OVERALL_RATING = 'overall_rating'\n",
        "RECOMMEND_TO_A_FRIEND = 'recommend_to_a_friend'\n",
        "REVIEW_TEXT = 'review_text'\n",
        "REVIEWER_GENDER = 'reviewer_gender'\n",
        "PROCESSED_TEXT = 'processed_text'\n",
        "\n",
        "# dtypes = {\n",
        "#     'submission_date': str,\n",
        "#     'reviewer_id': 'string',\n",
        "#     'product_id': 'string'\n",
        "#     'product_name': str,\n",
        "#     'product_brand': str,\n",
        "#     'site_category_lv1': str,\n",
        "#     'site_category_lv2': str,\n",
        "#     'review_title': str,\n",
        "#     'overall_rating': int,\n",
        "#     'recommend_to_a_friend': bool,\n",
        "#     'review_text': str,\n",
        "#     'reviewer_birth_year': float,\n",
        "#     'reviewer_gender': str,\n",
        "#     'reviewer_state': str\n",
        "# }\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/B2W-Reviews01.csv', parse_dates=[SUBMISSION_DATE], low_memory=False)\n",
        "print('dtypes:')\n",
        "print(df.dtypes)\n",
        "\n",
        "print('\\n\\n')\n",
        "print(f'Data size: { str(len(df)) }')\n",
        "\n",
        "print('\\n\\n')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploring the dataset"
      ],
      "metadata": {
        "id": "0xHYZM4giwec"
      },
      "id": "0xHYZM4giwec"
    },
    {
      "cell_type": "markdown",
      "id": "d55e4b3f",
      "metadata": {
        "id": "d55e4b3f"
      },
      "source": [
        "### Checking for columns with missing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b86e9f",
      "metadata": {
        "id": "69b86e9f"
      },
      "outputs": [],
      "source": [
        "def calculate_percentage(number_of_null_rows):\n",
        "  total_rows = len(df)\n",
        "  percentage = (number_of_null_rows / total_rows) * 100\n",
        "  formatted_percentage = format(percentage, \".2f\")\n",
        "  return f'{ formatted_percentage }%'\n",
        "\n",
        "def check_for_null(column_name):\n",
        "  number_of_null_rows = df[column_name].isnull().sum()\n",
        "  print(f'{ column_name }: { number_of_null_rows }, which is { calculate_percentage(number_of_null_rows) }')\n",
        "\n",
        "for column_name in df.columns:\n",
        "  check_for_null(column_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf18cef",
      "metadata": {
        "id": "8cf18cef"
      },
      "source": [
        "### Checking the distribution of ratings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc1ee0f9",
      "metadata": {
        "id": "fc1ee0f9"
      },
      "outputs": [],
      "source": [
        "def total_of_ratings(dataframe, rating):\n",
        "  total = (dataframe[OVERALL_RATING] == rating).sum()\n",
        "  print(f'{ rating } stars: { total }, which is { calculate_percentage(total) }')\n",
        "\n",
        "for rating in [1, 2, 3, 4, 5]:\n",
        "  total_of_ratings(df, rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d71c9d9a",
      "metadata": {
        "id": "d71c9d9a"
      },
      "source": [
        "It means that, if we take 3 stars as neutral, unfavorable reviews would be 27.02% and favorable reviews would be 60,66."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drawing a word cloud of the positive and negative reviews"
      ],
      "metadata": {
        "id": "VDEa8Eck4G0-"
      },
      "id": "VDEa8Eck4G0-"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def blue_shades_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "    # Generate varying shades of blue\n",
        "    hue = 210  # Hue for blue color in HSL\n",
        "    saturation = 100  # Saturation for blue color in HSL\n",
        "    lightness = random.randint(30, 70)  # Vary the lightness component\n",
        "\n",
        "    # Return the HSL color string\n",
        "    return f\"hsl({hue}, {saturation}%, {lightness}%)\"\n",
        "\n",
        "\n",
        "def red_shades_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "    # Generate varying shades of red\n",
        "    hue = random.randint(0, 20)  # Vary the hue component for different shades of red\n",
        "    saturation = 100  # Saturation for red color in HSL\n",
        "    lightness = 50  # Lightness for red color in HSL (you can adjust this)\n",
        "\n",
        "    # Return the HSL color string\n",
        "    return f\"hsl({hue}, {saturation}%, {lightness}%)\"\n",
        "\n",
        "\n",
        "filtered_df = df.dropna(subset = [REVIEW_TEXT])\n",
        "\n",
        "negative_reviews = filtered_df[filtered_df[OVERALL_RATING].isin([1, 2])]\n",
        "positive_reviews = filtered_df[filtered_df[OVERALL_RATING].isin([4, 5])]\n",
        "\n",
        "negative_text = \" \".join(negative_reviews[REVIEW_TEXT].str.lower())\n",
        "positive_text = \" \".join(positive_reviews[REVIEW_TEXT].str.lower())\n",
        "\n",
        "positive_wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=blue_shades_color_func).generate(positive_text)\n",
        "negative_wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=red_shades_color_func).generate(negative_text)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(positive_wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(negative_wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8m9oSpA84MWs"
      },
      "id": "8m9oSpA84MWs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2f5d3b44",
      "metadata": {
        "id": "2f5d3b44"
      },
      "source": [
        "## 4. Pre-Processing of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the samples"
      ],
      "metadata": {
        "id": "fLvLAJZYjL_c"
      },
      "id": "fLvLAJZYjL_c"
    },
    {
      "cell_type": "code",
      "source": [
        "# SAMPLE_SIZE = 15000\n",
        "SAMPLE_SIZE = 3000\n",
        "\n",
        "# Drop rows with null values in 'review_text' column and select a sample\n",
        "samples = df.dropna(subset = [REVIEW_TEXT])\n",
        "\n",
        "# Drops samples with 3 stars, as they will be considered neutral\n",
        "samples = samples[samples[OVERALL_RATING] != 3]\n",
        "\n",
        "samples = samples.sample(\n",
        "    n=SAMPLE_SIZE,\n",
        "    random_state=random_state\n",
        ")"
      ],
      "metadata": {
        "id": "7T7xCEjbjP4N"
      },
      "id": "7T7xCEjbjP4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'samples size is {len(samples)}')"
      ],
      "metadata": {
        "id": "UIqiKxm1POQS"
      },
      "id": "UIqiKxm1POQS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove stop words and apply stemming"
      ],
      "metadata": {
        "id": "TgkYnv8ijwBv"
      },
      "id": "TgkYnv8ijwBv"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Get the stopwords for Portuguese\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('rslp')\n",
        "\n",
        "SHOULD_PREPROCESS_TEXT = True\n",
        "\n",
        "portuguese_stopwords = set(stopwords.words('portuguese'))\n",
        "\n",
        "print(f'portuguese stopwords: {portuguese_stopwords}')\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  words = tokenizer.tokenize(text)\n",
        "  stemmer = RSLPStemmer()\n",
        "  filtered_words = [word for word in words if word.lower() not in portuguese_stopwords]\n",
        "  stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "  return ' '.join(stemmed_words)\n",
        "\n",
        "\n",
        "# Create a TF-IDF vectorizer to convert text data into numerical features\n",
        "if SHOULD_PREPROCESS_TEXT:\n",
        "  samples[PROCESSED_TEXT] = samples[REVIEW_TEXT].apply(preprocess)\n",
        "else:\n",
        "  samples[PROCESSED_TEXT] = samples[REVIEW_TEXT]\n",
        "\n",
        "\n",
        "print('\\n\\nSamples:')\n",
        "print(samples[PROCESSED_TEXT])"
      ],
      "metadata": {
        "id": "KlqDuKghj1cR"
      },
      "id": "KlqDuKghj1cR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Prepare training and test"
      ],
      "metadata": {
        "id": "D5EwfFNklr_1"
      },
      "id": "D5EwfFNklr_1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create X and Y values"
      ],
      "metadata": {
        "id": "KlqfSvnsmHsC"
      },
      "id": "KlqfSvnsmHsC"
    },
    {
      "cell_type": "code",
      "source": [
        "X = samples[PROCESSED_TEXT].values\n",
        "\n",
        "Y = samples[OVERALL_RATING]\n",
        "\n",
        "# Maps 1 and 2 stars as negative reviews, and 4 and 5 stars as positive reviews\n",
        "Y = Y.map({1:0, 2:0, 4: 1, 5: 1}).values\n",
        "\n",
        "print('X values:')\n",
        "print(X)\n",
        "\n",
        "print('\\nY values:')\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "GHoL9Q35mNwj"
      },
      "id": "GHoL9Q35mNwj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separate training and test"
      ],
      "metadata": {
        "id": "Hg8aLueVlzIs"
      },
      "id": "Hg8aLueVlzIs"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_PERCENTAGE = 0.2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_PERCENTAGE, random_state=random_state)"
      ],
      "metadata": {
        "id": "gEODxuqRl2al"
      },
      "id": "gEODxuqRl2al",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balance the training data"
      ],
      "metadata": {
        "id": "8aWv42Eo9V9I"
      },
      "id": "8aWv42Eo9V9I"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "print(f'X_train length: {len(X_train)}')\n",
        "print(X_train)\n",
        "\n",
        "reshaped_X_train = X_train.reshape(-1, 1)\n",
        "print(reshaped_X_train)\n",
        "\n",
        "print(f'\\n\\nY_train length: {len(Y_train)}')\n",
        "print(Y_train)\n",
        "\n",
        "Y_train_series = pd.Series(Y_train)\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, Y_train_resampled = undersampler.fit_resample(reshaped_X_train, Y_train)\n",
        "\n",
        "X_train_resampled = X_train_resampled.flatten()\n",
        "\n",
        "print(f'\\n\\nX_train_resampled length: {len(X_train_resampled)}')\n",
        "print(X_train_resampled)\n",
        "\n",
        "print(f'\\n\\nY_train_resampled length: {len(Y_train_resampled)}')\n",
        "\n",
        "X_train_resampled = shuffle(X_train_resampled, random_state=random_state)\n",
        "Y_train_resampled = shuffle(Y_train_resampled, random_state=random_state)\n",
        "\n",
        "print(f'\\n\\nX_test length: {len(X_test)}')\n",
        "print(X_test)\n",
        "\n",
        "print(f'\\n\\nY_test length: {len(Y_test)}')\n",
        "print(Y_test)"
      ],
      "metadata": {
        "id": "CaT7rTmKN1X6"
      },
      "id": "CaT7rTmKN1X6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train and evaluate"
      ],
      "metadata": {
        "id": "jQDStIz1ueUz"
      },
      "id": "jQDStIz1ueUz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize, fit and transform"
      ],
      "metadata": {
        "id": "PpkMZUWMt3h-"
      },
      "id": "PpkMZUWMt3h-"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train_resampled)\n",
        "X_test_vectorized = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "SV5yPvTjt546"
      },
      "id": "SV5yPvTjt546",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run model to evaluate"
      ],
      "metadata": {
        "id": "_nRFG0zuusaz"
      },
      "id": "_nRFG0zuusaz"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import time\n",
        "\n",
        "confusion_matrices = []\n",
        "\n",
        "def evaluate_model(model_name, model_instance):\n",
        "  t1 = time.time()\n",
        "  # Train the model\n",
        "  model_instance.fit(X_train_vectorized, Y_train_resampled)\n",
        "  # Make predictions on the test data\n",
        "  Y_pred = model_instance.predict(X_test_vectorized)\n",
        "  # Calculate accuracy\n",
        "  accuracy = accuracy_score(Y_test, Y_pred)\n",
        "  recall = recall_score(Y_test, Y_pred, average='macro')\n",
        "  f1 = f1_score(Y_test, Y_pred, average='macro')\n",
        "  print(f'Accuracy of {model_name}: {accuracy}')\n",
        "  print(f'Recall of {model_name}: {recall}')\n",
        "  print(f'F1 of {model_name}: {f1}')\n",
        "\n",
        "  t2 = time.time()\n",
        "  print(f'\\nTook: {t2 - t1} seconds to run')\n",
        "\n",
        "  fpr, tpr, _ = roc_curve(Y_test, Y_pred)\n",
        "  roc_auc = roc_auc_score(Y_test, Y_pred)\n",
        "\n",
        "  plot_roc_curve(fpr, tpr, roc_auc)\n",
        "\n",
        "  data = confusion_matrix(Y_test, Y_pred)\n",
        "  data.astype(int)\n",
        "  confusion_matrices.append(data)\n",
        "\n",
        "\n",
        "def plot_roc_curve(fpr, tpr, roc_auc):\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(matrix, labels, ax):\n",
        "  \"\"\"Plot a single confusion matrix in a subplot.\"\"\"\n",
        "  seaborn.set(color_codes=True)\n",
        "  seaborn.set(font_scale=1.4)\n",
        "  seaborn.heatmap(matrix, annot=True, fmt='d', cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'}, ax=ax)\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.set_yticklabels(labels)\n",
        "  ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
        "\n",
        "\n",
        "def plot_confusion_matrices(matrices_list, labels, titles):\n",
        "  \"\"\"Plot multiple confusion matrices in a 4x4 grid.\"\"\"\n",
        "  num_matrices = len(matrices_list)\n",
        "  num_rows = 2  # Number of rows in the grid\n",
        "  num_cols = 2  # Number of columns in the grid\n",
        "\n",
        "  # Create a grid of subplots\n",
        "  fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))\n",
        "\n",
        "  for i in range(num_matrices):\n",
        "    row = i // num_cols\n",
        "    col = i % num_cols\n",
        "    ax = axes[row, col]\n",
        "    plot_confusion_matrix(matrices_list[i], labels, ax)\n",
        "    ax.set_title(titles[i])\n",
        "\n",
        "  # Adjust layout and display\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lCM3a9KHuvpC"
      },
      "id": "lCM3a9KHuvpC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "evaluate_model('Support Vector Machines', SVC(kernel='linear'))"
      ],
      "metadata": {
        "id": "iKNOt-0FvPU5"
      },
      "id": "iKNOt-0FvPU5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1387ce5",
      "metadata": {
        "id": "a1387ce5"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "evaluate_model('Naive Bayes', MultinomialNB())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4f070e",
      "metadata": {
        "id": "8f4f070e"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "evaluate_model('Logistic Regression', LogisticRegression(n_jobs=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c63dda",
      "metadata": {
        "id": "f1c63dda"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "evaluate_model('Random Forest', RandomForestClassifier(n_jobs=-1, random_state=random_state))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrices(confusion_matrices, labels=['negative', 'positive'], titles=['SVM', 'Naive Bayes', 'Regressão Logística', 'Random Forest'])"
      ],
      "metadata": {
        "id": "VZO_bUaJKrxs"
      },
      "id": "VZO_bUaJKrxs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "uT0p7ZHDih2U",
        "0xHYZM4giwec"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}